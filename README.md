# Reto -- Capa de Datos IoT

**Curso:** Internet de las Cosas (IoT)\
**Universidad de los Andes**\
**Repositorio:** https://github.com/JazminCorAndes/iot-capa-de-datos

------------------------------------------------------------------------

## üìå Descripci√≥n del Reto

En este repositorio se encuentran las modificaciones realizadas a las
aplicaciones desarrolladas en el tutorial de la capa de datos,
implementando una nueva consulta en:

-   Aplicaci√≥n con PostgreSQL
-   Aplicaci√≥n con TimescaleDB

El objetivo fue dise√±ar una consulta interesante sobre la entidad `Data`
y sus entidades relacionadas, exponerla mediante un endpoint REST que
retorna un JSON, redesplegar las aplicaciones en la nube y comparar su
desempe√±o mediante pruebas de carga con JMeter.

------------------------------------------------------------------------

## üîß Modificaciones Realizadas

Para facilitar la comparaci√≥n, se subieron primero los archivos
originales del tutorial y posteriormente se aplicaron los cambios
necesarios.

### Nueva Consulta Implementada

Endpoint creado:

    /dailyAvg/

### üéØ Prop√≥sito de la Consulta

Calcular el promedio diario de temperatura por ciudad durante los
√∫ltimos 7 d√≠as.

Esta consulta permite:

-   An√°lisis agregados sobre datos de sensores.
-   Simular consultas reales de monitoreo ambiental.
-   Implementar agregaci√≥n temporal (clave en sistemas IoT).

------------------------------------------------------------------------

## üóÑ Implementaci√≥n en PostgreSQL

``` python
from django.http import JsonResponse
from django.db import connection
from django.utils import timezone
from datetime import timedelta

def daily_avg_by_city(request):
    end = timezone.now()
    start = end - timedelta(days=7)

    with connection.cursor() as cursor:
        cursor.execute("""
            SELECT 
                c.name AS city,
                m.name AS measurement,
                DATE(d.base_time) AS day,
                AVG(d.avg_value) AS avg_value
            FROM "realtimeGraph_data" d
            JOIN "realtimeGraph_station" s ON d.station_id = s.id
            JOIN "realtimeGraph_location" l ON s.location_id = l.id
            JOIN "realtimeGraph_city" c ON l.city_id = c.id
            JOIN "realtimeGraph_measurement" m ON d.measurement_id = m.id
            WHERE d.base_time >= %s AND d.base_time <= %s
            GROUP BY city, measurement, day
            ORDER BY city, measurement, day;
        """, [start, end])

        rows = cursor.fetchall()

    data = []
    for city, measurement, day, avg_value in rows:
        data.append({
            "city": city,
            "measurement": measurement,
            "day": day.isoformat(),
            "avg_value": float(avg_value) if avg_value is not None else None
        })

    return JsonResponse(data, safe=False)

```

------------------------------------------------------------------------

## ‚è± Implementaci√≥n en TimescaleDB

``` python
from django.http import JsonResponse
from django.db import connection
from django.utils import timezone
from datetime import timedelta

def daily_avg_by_city(request):
    end = timezone.now()
    start = end - timedelta(days=7)

    with connection.cursor() as cursor:
        cursor.execute("""
            SELECT 
                c.name AS city,
                m.name AS measurement,
                time_bucket('1 day', d.base_time) AS day,
                AVG(d.avg_value) AS avg_value
            FROM "realtimeGraph_data" d
            JOIN "realtimeGraph_station" s ON d.station_id = s.id
            JOIN "realtimeGraph_location" l ON s.location_id = l.id
            JOIN "realtimeGraph_city" c ON l.city_id = c.id
            JOIN "realtimeGraph_measurement" m ON d.measurement_id = m.id
            WHERE d.base_time >= %s AND d.base_time <= %s
            GROUP BY city, measurement, day
            ORDER BY city, measurement, day;
        """, [start, end])

        rows = cursor.fetchall()

    data = []
    for city, measurement, day, avg_value in rows:
        data.append({
            "city": city,
            "measurement": measurement,
            "day": day.isoformat(),
            "avg_value": float(avg_value) if avg_value is not None else None
        })

    return JsonResponse(data, safe=False)

```

------------------------------------------------------------------------

## üåê Redespliegue en la Nube

Las aplicaciones fueron redesplegadas en instancias de AWS EC2,
reiniciando los servicios despu√©s de aplicar las modificaciones.

Verificaci√≥n mediante:

    http://<IP_PUBLICA>/dailyAvg/

------------------------------------------------------------------------

## üìä Pruebas de Carga

Se realizaron pruebas de carga utilizando Apache JMeter:

-   60 requests
-   Comparaci√≥n entre PostgreSQL y TimescaleDB
-   M√©tricas evaluadas:
    -   Latencia promedio
    -   Throughput
    -   Desviaci√≥n est√°ndar
    -   Error %

Los scripts de prueba se incluyen en el repositorio.

------------------------------------------------------------------------

## üìà Resultados Observados

-   En consultas hist√≥ricas amplias (tutorial original), TimescaleDB
    mostr√≥ mejor rendimiento.
-   En ventanas cortas (7 d√≠as), PostgreSQL present√≥ tiempos
    competitivos.
-   Ambos motores tuvieron 0% de errores.

------------------------------------------------------------------------

## üß† Conclusi√≥n T√©cnica

En sistemas IoT:

-   El volumen y patr√≥n de acceso a los datos determinan el rendimiento.
-   TimescaleDB ofrece ventajas claras en an√°lisis temporal intensivo.
-   PostgreSQL puede ser suficiente en escenarios de menor escala.

La elecci√≥n del motor debe basarse en:

-   Frecuencia de escritura\
-   Tama√±o hist√≥rico de los datos\
-   Tipo de consultas anal√≠ticas requeridas


------------------------------------------------------------------------

## üë• Autores

Juan Esteban Mejia Izasa
Jazmin Natalia Cordoba Puerto
